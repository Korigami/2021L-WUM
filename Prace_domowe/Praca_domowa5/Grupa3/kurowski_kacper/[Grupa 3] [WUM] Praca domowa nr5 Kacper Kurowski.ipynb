{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [WUM] Praca domowa nr 5\n",
    "## Kacper Kurowski\n",
    "\n",
    "Zacznijmy od wczytania danych "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"clustering.csv\",  header = None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans_clusters(X, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    y_kmeans = kmeans.predict(X)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=30, cmap='viridis')\n",
    "\n",
    "    centers = kmeans.cluster_centers_\n",
    "    plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.75)\n",
    "    plt.title('K-means clusters')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kmeans_clusters( data, n_clusters=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postarajmy się znaleźć optymalną liczbę klastrów przy pomocy minimalizacji sumy kwadratów wewnątrz klastrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def count_wcss_scores(X, k_max):\n",
    "    #  WCSS = within-cluster sum of squares\n",
    "    scores = []\n",
    "    for k in range(1, k_max+1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0)\n",
    "        kmeans.fit(X)\n",
    "        wcss = kmeans.score(X) * -1 # score returns -WCSS\n",
    "        scores.append(wcss)\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss_vec = count_wcss_scores( data, 10)\n",
    "x_ticks = list(range(1, len(wcss_vec) + 1))\n",
    "plt.plot(x_ticks, wcss_vec, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Within-cluster sum of squares')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Niestety, metoda ta nie daje tym razem dobrej sugestii co do tego jaką liczbę klastrów warto by wybrać. Z tego powodu skorzystajmy z innej metody."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clustering_scores(X, cluster_num, model, score_fun):\n",
    "    if isinstance(cluster_num, int):\n",
    "        cluster_num_iter = [cluster_num]\n",
    "    else:\n",
    "        cluster_num_iter = cluster_num\n",
    "        \n",
    "    scores = []    \n",
    "    for k in cluster_num_iter:\n",
    "        model_instance = model(n_clusters=k)\n",
    "        labels = model_instance.fit_predict(X)\n",
    "        wcss = score_fun(X, labels)\n",
    "        scores.append(wcss)\n",
    "    \n",
    "    if isinstance(cluster_num, int):\n",
    "        return scores[0]\n",
    "    else:\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "cluster_num_seq = range(2, 11) \n",
    "silhouette_vec = count_clustering_scores( data, cluster_num_seq, KMeans, silhouette_score)\n",
    "plt.plot(cluster_num_seq, silhouette_vec, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaje się zatem, że to 8 jest najodpowiedniejszą liczbą kalstrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_kmeans_clusters( data, n_clusters=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rzeczywiście uzyskiwane klastry wydają się być \"rozsądne\". Należy jednak zaznaczyć, że klastry te zdają się być dość \"okrągłe\", więc rezultat ten być może nie odzwierciedla ewentualnej \"spójności\" klastrów - przykładowo, 3 klastry ze współrzędną y ok. - zdają się tworzyć niemal spójny twór, czego uzyskany podział nie odzwierciedla.\n",
    "\n",
    "Zastosujmy również metodę, która może nieco bardziej będzie wyłapywać wspomnianą spójność"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=8)\n",
    "y = model.fit_predict( data)\n",
    "plt.scatter( data[:, 0], data[:, 1], c=y, s=30, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać na powyższym wykresie, kilka punktów, które wcześniej były w klastrze najbardziej na prawo, teraz przeszło do purpurawego po środku. Podobnie kilka punktów z dolnego po środku przeszło do wspomnianego purpurawego.\n",
    "\n",
    "Gdybyśmy natomiast zdecydowali się zmienić liczbę klastrów na 5, uzyskalibyśmy poniiższy rezultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "model = AgglomerativeClustering(n_clusters=5)\n",
    "y = model.fit_predict( data)\n",
    "plt.scatter( data[:, 0], data[:, 1], c=y, s=30, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Który zdaje się nieco bardziej odzwrierciedlać wspomane \"spójności\". Wreszcie, możemy skorzystać z algorytmów hierarhicznych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "\n",
    "Z = hierarchy.linkage( data, method='average')\n",
    "plt.figure(figsize=(10, 5), dpi= 200, facecolor='w', edgecolor='k')\n",
    "hierarchy.dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tym razem odpowiedź nie jest juz taka oczywista. Teoretycznie wciąż 8 klastrów daje dobre rezultaty, ale prawa strona wykresu sugeruje, że zysk z podzielenia na więcej klastrów nie jest już tak duży jak przy tych pierwszych podziałach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
